Using 16bit Automatic Mixed Precision (AMP)
/Users/edoardo/anaconda3/lib/python3.11/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
GPU available: True (mps), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
/Users/edoardo/anaconda3/lib/python3.11/site-packages/pytorch_lightning/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.

  | Name        | Type              | Params | Mode
----------------------------------------------------------
0 | fc_layer    | Linear            | 58.1 K | train
1 | conv_layers | Sequential        | 79.6 K | train
2 | loss_fn     | MSELoss           | 0      | train
3 | mse         | MeanSquaredError  | 0      | train
4 | mae         | MeanAbsoluteError | 0      | train
5 | r2          | R2Score           | 0      | train
6 | md          | MinkowskiDistance | 0      | train
----------------------------------------------------------
137 K     Trainable params
0         Non-trainable params
137 K     Total params
0.551     Total estimated model params size (MB)
16        Modules in train mode
0         Modules in eval mode
Training is starting!                                                                         
/Users/edoardo/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
/Users/edoardo/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
/Users/edoardo/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
Epoch 99: 100%|â–ˆ| 1734/1734 [02:30<00:00, 11.54it/s, v_num=syot, val_loss=0.00235, val_mae=0.0Training is done!
/Users/edoardo/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
Best validation loss: 0.002352239331230521                                                    
`Trainer.fit` stopped: `max_epochs=100` reached.
Epoch 99: 100%|â–ˆ| 1734/1734 [02:30<00:00, 11.54it/s, v_num=syot, val_loss=0.00235, val_mae=0.0
/Users/edoardo/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
Validation DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 217/217 [00:09<00:00, 21.73it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m [0m[1m     Validate metric     [0m[1m [0mâ”ƒ[1m [0m[1m      DataLoader 0       [0m[1m [0mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚[36m [0m[36m        val_loss         [0m[36m [0mâ”‚[35m [0m[35m  0.002352239331230521   [0m[35m [0mâ”‚
â”‚[36m [0m[36m         val_mae         [0m[36m [0mâ”‚[35m [0m[35m  0.022759143263101578   [0m[35m [0mâ”‚
â”‚[36m [0m[36m         val_md          [0m[36m [0mâ”‚[35m [0m[35m   3.0823559761047363    [0m[35m [0mâ”‚
â”‚[36m [0m[36m         val_mse         [0m[36m [0mâ”‚[35m [0m[35m  0.002352239331230521   [0m[35m [0mâ”‚
â”‚[36m [0m[36m         val_r2          [0m[36m [0mâ”‚[35m [0m[35m    0.997374415397644    [0m[35m [0mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
/Users/edoardo/anaconda3/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.
Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 217/217 [00:10<00:00, 21.43it/s]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m [0m[1m       Test metric       [0m[1m [0mâ”ƒ[1m [0m[1m      DataLoader 0       [0m[1m [0mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚[36m [0m[36m        test_loss        [0m[36m [0mâ”‚[35m [0m[35m  0.0023076750803738832  [0m[35m [0mâ”‚
â”‚[36m [0m[36m        test_mae         [0m[36m [0mâ”‚[35m [0m[35m  0.022859033197164536   [0m[35m [0mâ”‚
â”‚[36m [0m[36m         test_md         [0m[36m [0mâ”‚[35m [0m[35m   2.9824612140655518    [0m[35m [0mâ”‚
â”‚[36m [0m[36m        test_mse         [0m[36m [0mâ”‚[35m [0m[35m  0.0023076750803738832  [0m[35m [0mâ”‚
â”‚[36m [0m[36m         test_r2         [0m[36m [0mâ”‚[35m [0m[35m    0.99733966588974     [0m[35m [0mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
